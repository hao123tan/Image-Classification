{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Add, Concatenate, Conv2D, Conv2DTranspose, UpSampling2D, MaxPooling2D, MaxPool2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adadelta\n",
    "import tensorflow.keras.backend as K\n",
    "# from tensorflow.keras.objectives import mean_squared_error\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_images.shape:  (50000, 32, 32, 3)\n",
      "X_test_images.shape:  (10000, 32, 32, 3)\n",
      "y_train_labels.shape:  (50000, 1)\n",
      "y_test_labels.shape:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(X_train_images, y_train_labels), (X_test_images, y_test_labels) = cifar10.load_data()\n",
    "\n",
    "print('X_train_images.shape: ', X_train_images.shape)\n",
    "print('X_test_images.shape: ', X_test_images.shape)\n",
    "print('y_train_labels.shape: ', y_train_labels.shape)\n",
    "print('y_test_labels.shape: ', y_test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function used for visualizing the predicted and true labels of test data\n",
    "def show_test(m, X_test, y_test, d):\n",
    "    plt.figure(figsize =(40,8))\n",
    "    for i in range(5):\n",
    "        ax = plt.subplot(1, 5, i+1)\n",
    "        test_image = np.expand_dims(d[1810*i+5], axis=0)\n",
    "        test_result = m.predict(test_image)\n",
    "        plt.imshow(X_test[1810*i+5])\n",
    "        index = np.argsort(test_result[0,:])\n",
    "        plt.title(\"Pred:{}, True:{}\".format(dict[index[9]], dict[y_test[1810*i+5][0]]))\n",
    "    plt.show()\n",
    "\n",
    "## function used for creating a classification report and confusion matrix\n",
    "def report(predictions, y_test):\n",
    "    cm=confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))\n",
    "    \n",
    "    print(\"Classification Report:\\n\")\n",
    "    cr=classification_report(y_test.argmax(axis=1),\n",
    "                                predictions.argmax(axis=1), \n",
    "                                target_names=list(dict.values()))\n",
    "    print(cr)\n",
    "    \n",
    "    #plot confusion_matrix\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, xticklabels = list(dict.values()), yticklabels = list(dict.values()), fmt=\"d\")\n",
    "    \n",
    "## function used for visualizing original and reconstructed images of the autoencoder model\n",
    "def showOrigAndReconstructedImages(orig_imgs, decoded_imgs, img_width, img_height, channels, num=10):\n",
    "    n = num\n",
    "    plt.figure(figsize=(20, 4))\n",
    "\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        plt.imshow(orig_imgs[300*i].reshape(img_width, img_height, channels))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i +1 + n)\n",
    "        plt.imshow(decoded_imgs[300*i].reshape(img_width, img_height, channels))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "    \n",
    "def train_model(model, X_train, y_train, X_valid, y_valid, data_aug = False, epochs=50, batch_size=512):\n",
    "    er = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "#     cp = ModelCheckpoint(filepath = 'best_model.h5',save_best_only = True,verbose=1)\n",
    "    lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_delta=0.0001)\n",
    "    callbacks = [er, lr]\n",
    "    \n",
    "    if not data_aug:  \n",
    "        print('Training without data augmentation...')\n",
    "        history = model.fit(X_train, y_train, batch_size=batch_size,\n",
    "                                 epochs=epochs,\n",
    "                                 verbose=1, callbacks=callbacks,\n",
    "                                 validation_data=(X_valid,y_valid))\n",
    "        return history\n",
    "    else:\n",
    "        print('Training with data augmentation...')\n",
    "        train_datagen = ImageDataGenerator(shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "        train_set_ae = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "        validation_datagen = ImageDataGenerator()\n",
    "        validation_set_ae = validation_datagen.flow(X_valid, y_valid, batch_size=batch_size)\n",
    "        \n",
    "        history = model.fit_generator(train_set_ae,\n",
    "                                           epochs=epochs,\n",
    "                                           steps_per_epoch=np.ceil(X_train.shape[0]/batch_size),\n",
    "                                           verbose=1, callbacks=callbacks,\n",
    "                                           validation_data=(validation_set_ae),\n",
    "                                           validation_steps=np.ceil(X_valid.shape[0]/batch_size))\n",
    "        \n",
    "        return history\n",
    "    \n",
    "def plot_loss_accuracy(history, plot_loss_only= False):\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(16, 4))\n",
    "    ax1.plot(history.history['loss'])\n",
    "    ax1.plot(history.history['val_loss'])\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Val'], loc='lower right')    \n",
    "        \n",
    "    if not plot_loss_only:\n",
    "        ax2.plot(history.history['acc'])\n",
    "        ax2.plot(history.history['val_acc'])\n",
    "        ax2.set_title('Model accuracy')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.legend(['Train', 'Val'], loc='lower right')    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_classes = 10\n",
    "dict = {0:'Airplane', 1:'Automobile', 2:'Bird', 3:'Cat', 4:'Deer', 5:'Dog', 6:'Frog', 7:'Horse', 8:'Ship', 9:'Truck'}\n",
    "img_width, img_height = 32, 32\n",
    "epochs = 50\n",
    "batch_size = 512\n",
    "\n",
    "if K.image_data_format()=='channels_first':\n",
    "    input_shape=(3, img_width, img_height)\n",
    "else:\n",
    "    input_shape=(img_width,img_height,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train_images, X_test_images, y_train_labels, y_test_labels, no_of_classes):\n",
    "    #normalize\n",
    "    X_train_images = X_train_images.astype('float32')/255.\n",
    "    X_test = X_test_images.astype('float32')/255.\n",
    "    \n",
    "    #split training data further into training and validation set\n",
    "    X_train, X_valid, y_train_labels, y_valid_labels = train_test_split(X_train_images, y_train_labels, test_size=0.2, random_state=42, shuffle= True)\n",
    "    print('X_train.shape: ', X_train.shape)\n",
    "    print('X_valid.shape: ', X_valid.shape)\n",
    "    print('y_train_labels.shape: ', y_train_labels.shape)\n",
    "    print('y_valid_labels.shape: ', y_valid_labels.shape)\n",
    "    \n",
    "    #The target variable is converted to one-hot encoded data using the utils.to_categorical function of the keras library.\n",
    "    y_train = to_categorical(y_train_labels, no_of_classes)\n",
    "    y_valid = to_categorical(y_valid_labels, no_of_classes)\n",
    "    y_test = to_categorical(y_test_labels, no_of_classes)\n",
    "    print('y_train.shape: ', y_train.shape)\n",
    "    print('y_test.shape: ', y_test.shape)\n",
    "    \n",
    "    return ((X_train, y_train), (X_valid, y_valid), (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (40000, 32, 32, 3)\n",
      "X_valid.shape:  (10000, 32, 32, 3)\n",
      "y_train_labels.shape:  (40000, 1)\n",
      "y_valid_labels.shape:  (10000, 1)\n",
      "y_train.shape:  (40000, 10)\n",
      "y_test.shape:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_valid, y_valid), (X_test, y_test) = preprocess_data(X_train_images, X_test_images, y_train_labels, y_test_labels, no_of_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN model as Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,176,394\n",
      "Trainable params: 2,176,010\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_simple_conv_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64,(3,3),input_shape=input_shape, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(MaxPool2D(pool_size=(2,2)))    \n",
    "    \n",
    "    model.add(Conv2D(128,(3,3),input_shape=input_shape, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(no_of_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "        \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adadelta(), metrics=['acc'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "conv_model = create_simple_conv_model()\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train_model(conv_model, X_train, y_train, X_valid, y_valid, data_aug = True, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy for benchmark model= {}'.format(conv_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = conv_model.predict(X_test)\n",
    "report(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Convolution Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_block(input, chs): ## Convolution block of 2 layers\n",
    "    x = input\n",
    "    for i in range(2):\n",
    "        x = Conv2D(chs, 3, padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def loss_function(y_true, y_pred):  ## loss function for using in autoencoder models\n",
    "    mses = mean_squared_error(y_true, y_pred)\n",
    "    return K.sum(mses, axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convolution_ae():\n",
    "    input_img = Input((32,32,3))\n",
    "    \n",
    "    #encoder\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)    \n",
    "\n",
    "    # at this point the representation is ...\n",
    "\n",
    "    #decoder\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    \n",
    "    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    encoder = Model(input_img, encoded)\n",
    "    return encoder, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_convolution_ae2():\n",
    "#     input = Input((32,32,3))\n",
    "    \n",
    "#     # Encoder\n",
    "#     block1 = create_block(input, 32)\n",
    "#     x = MaxPool2D(2)(block1)\n",
    "#     block2 = create_block(x, 64)\n",
    "#     x = MaxPool2D(2)(block2)\n",
    "    \n",
    "#     #Middle\n",
    "#     middle = create_block(x, 128)\n",
    "    \n",
    "#     # Decoder\n",
    "#     up1 = UpSampling2D((2,2))(middle)\n",
    "#     block3 = create_block(up1, 64)\n",
    "#     #up1 = UpSampling2D((2,2))(block3)\n",
    "#     up2 = UpSampling2D((2,2))(block3)\n",
    "#     block4 = create_block(up2, 32)\n",
    "#     #up2 = UpSampling2D((2,2))(block4)\n",
    "    \n",
    "#     # output\n",
    "#     x = Conv2D(3, 1)(up2)\n",
    "#     output = Activation(\"sigmoid\")(x)\n",
    "#     return Model(input, middle), Model(input, output)\n",
    "\n",
    "# encoder_conv, autoencoder_conv = create_convolution_ae2()\n",
    "# # autoencoder.compile(loss='categorical_crossentropy', optimizer=Adadelta())  # model_ae.compile(SGD(1e-3, 0.9), loss=loss_function) \n",
    "# autoencoder_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_conv, autoencoder_conv = create_convolution_ae()\n",
    "# autoencoder.compile(loss='categorical_crossentropy', optimizer=Adadelta())  # model_ae.compile(SGD(1e-3, 0.9), loss=loss_function) \n",
    "autoencoder_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the autoencoder convolution model. No need to use labels as it is unsupervised learning\n",
    "history = train_model(autoencoder_conv, X_train, X_train, X_valid, X_valid, data_aug = False, epochs=epochs, batch_size=batch_size)\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history, plot_loss_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_test_imgs_conv_ae = autoencoder_conv.predict(X_test)\n",
    "decoded_valid_imgs_conv_ae = autoencoder_conv.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOrigAndReconstructedImages(X_valid, decoded_valid_imgs_conv_ae, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOrigAndReconstructedImages(X_test, decoded_test_imgs_conv_ae, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify images using features extracted from above Autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_dense(inp):\n",
    "    input = Input((inp.shape[1], inp.shape[2], inp.shape[3]))\n",
    "    #x = MaxPool2D()(input)\n",
    "    x = Flatten()(input)\n",
    "    #x = BatchNormalization()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.64)(x)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    #x = Reshape((-1, 1))(x)\n",
    "    #x = Conv1D(128, (3,), activation='relu', padding='same')(x)\n",
    "    #x = MaxPool1D()(x)\n",
    "    #x = CuDNNLSTM(64)(x)\n",
    "    #x = Flatten()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    output = Dense(no_of_classes, activation='softmax')(x)\n",
    "    return Model(input, output)\n",
    "\n",
    "def classifier_conv(inp):\n",
    "    input = Input((inp.shape[1], inp.shape[2], inp.shape[3]))\n",
    "    x = Conv2D(1024, 3, padding=\"same\")(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool2D(2)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Conv2D(128, 3, padding=\"same\")(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool2D(2)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.35)(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dropout(0.69)(x)\n",
    "    \n",
    "    output = Dense(no_of_classes, activation='softmax')(x)\n",
    "    return Model(input, output)\n",
    "\n",
    "def create_classifier(m, inp):  ## function for choosing dense/convolutional classifier model\n",
    "    if m=='dense':\n",
    "        classifier = classifier_dense(inp)\n",
    "    elif m=='conv':\n",
    "        classifier = classifier_conv(inp)    \n",
    "    classifier.compile(loss='categorical_crossentropy', optimizer=Adadelta(), metrics=['acc'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting bottleneck features to use as inputs in the classifier model:\n",
    "gist_train_ae = encoder_conv.predict(X_train)\n",
    "gist_valid_ae = encoder_conv.predict(X_valid)\n",
    "gist_test_ae = encoder_conv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder with simple NN or multi-layer perceptron as classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_ae_dense = create_classifier('dense', gist_train_ae)\n",
    "decoder_ae_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train_model(decoder_ae_dense, gist_train_ae, y_train, gist_valid_ae, y_valid, data_aug = False, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy for AE_dense model= {}'.format(decoder_ae_dense.evaluate(gist_test_ae, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_test(decoder_ae_dense, X_test, y_test, gist_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = decoder_ae_dense.predict(gist_test_ae)\n",
    "report(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder with CNN as classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_ae_conv = create_classifier('conv', gist_train_ae)\n",
    "decoder_ae_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = train_model(decoder_ae_conv, gist_train_ae, y_train, gist_valid_ae, y_valid, data_aug = False, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy for AE_conv model= {}'.format(decoder_ae_conv.evaluate(gist_test_ae, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_test(decoder_ae_conv, X_test, y_test, gist_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = decoder_ae_conv.predict(gist_test_ae)\n",
    "report(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "* https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "* https://www.kaggle.com/aninditapani/cifar-10-cnn-from-scratch\n",
    "* https://www.kaggle.com/mahtabshaan/autoencoder-as-feature-extractor-cifar10\n",
    "* https://www.kaggle.com/amithasanshuvo/cifar-images-classification-using-cnn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
